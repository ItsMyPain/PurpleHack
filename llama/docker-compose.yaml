version: '3.7'

volumes:
  ubuntu_cache:
    name: ubuntu_cache

services:
  llama-server:
    env_file:
      - .env
    build: .
    container_name: llama-server
    environment:
      - PYTHONUNBUFFERED=True
    restart: always
    ports:
      - '8888:8888'
    volumes:
      - ubuntu_cache:/home/ubuntu/.cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    command: python3 ./server.py
